# 评价类模型

## 1 层次分析法

> 为什么需要评价类模型？
>
> - 同一个问题，不同方案之间需要评价 
> - 同一个问题，不同对象之间需要评价 
> - 同一个问题，不同准则之间需要评价 
> - 评价体系的不统一和片面化

### 1.1 概述

层次分析法(The Analytic Hierarchy Process，简称**AHP**)，是一种**定性和定量相结合**的、系统化的、层次化的分析方法，用来处理复杂的决策问题，比如从多种方案中选择一种最优的。

> 比如，我们计划出去玩儿，想去的地方有拉萨、三亚、北京三个城市，都想去不知道该选择哪
> 个，这时候，就可以用上层次分析法。
>
> - 目标：选择最适合出游的地点
> - 准则：选择出去玩儿的地方,总会有些标准、准则来判断是否适合当前出去玩儿，比如，天
>   气，住宿，交通等等
> - 候选城市：拉萨、三亚、北京
>
> 我们需要考虑很多因素，这些因素在数学中就称为**变量**

### 1.2 方法介绍

#### 1.2.1 层次分析法的层次

1. 决策目标
2. 决策标准变量
3. 方案

> <img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725084402105.png" alt="image-20220725084402105" style="zoom:60%;" />
>
> 一对多、多对多

#### 1.2.2 成对比较矩阵

- 用上面例子的**目标层**与**准则层**列矩阵（**一对多**）

  <img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725084556918.png" alt="image-20220725084556918" style="zoom:67%;" />

  > **优先给重要的填**，最好选择**奇数**值，因为可以拉开一定差距（当然有些是**分数**）

- 成对比较矩阵的性质：

  - 方阵
  - **对角线元素为1** 
  - 对称元素求**乘积为1** 
  - 比较值尽可能取**奇数**

- **准则层**与**方案层**也可以形成成对比较矩阵（**多对多**），通常是每一个准则列一个方案矩阵

  > 一般来说是**自顶向下**的构建矩阵

- 成对比较矩阵需要由专家才有意义，这也是层次分析法的局限性所在

#### 1.2.3 RI-CI检验(一致性检验)

- 对比较矩阵进行特征值分解，最大的特征值为$\lambda$，那么定义CI：
  $$
  CI=\frac{\lambda-n}{n-1}
  $$
  

- 另外定义RI表格（随机实验统计规律）

  <img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725085124454.png" alt="image-20220725085124454" style="zoom:67%;" />

  > n是矩阵的维度

- 计算CR值
  $$
  CR=\frac{CI}{RI}
  $$

- 一般，当一致性比率CR<0.1时，认为A的不一致程度在容许范围内，有满意的一致性，通过一致性检验。

层次分析法的流程：

1. AHP

   1. 顶层：评价目标层

      通常目标是明确的，问题中会存在明确的目标

   2. 中间层：准则变量层

      变量通常需要查找大量文献，以及为什么选择这些变量。这些是可以说理的大户。或者德尔菲法发放专家问卷。

      > 层次分析法常用于社会科学、经济管理科学，其难点往往在于**准则变量**的确定

   3. 底层：候选方案层

      样本可以构成方案

2. 计算

   1. 构造：构造比较矩阵

      每对不同层次之间就要构造一个，这一过程存在较强主观性

   2. 检验：CR检验

      通不过需要改矩阵，这是很正常的

   3. 解说：结果的解说

      结果需要解说

      > **权重**与**得分**是选择方案的重要参考，具体方法见下面的例子

### 1.3 具体案例与代码实现

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725085954525.png" alt="image-20220725085954525" style="zoom:67%;" />

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725090036163.png" alt="image-20220725090036163" style="zoom:67%;" />

> :star:成对比较矩阵快速计算最大特征值的方法，也是得出**权重**的方法：
>
> 1. 对矩阵$A$列做归一化（这里的方法就是直接除以总和，我也不知道这叫不叫归一）
> 2. 将每一行求和，得到一个新的列向量$\omega$
> 3. 对新的列向量$\omega$再次归一化，则有：$A\omega=\lambda\omega$
>
> 所以说**最大特征值**对应的**特征向量**标准化之后就是**权重向量**

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725091233273.png" alt="image-20220725091233273" style="zoom:67%;" />

> 第一行的权重是**目标层-准则层**矩阵求出来的，每一列的权重是**准则层-方案层**求出来的，总权重就是向量分别相乘得到的







## 2 熵权与TOPSIS

### 2.1 熵权法

> 主要是用来确定某一个指标的**权重**的

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725103607608.png" alt="image-20220725103607608" style="zoom:67%;" />

- x是某个指标的一组数据，目标是要求这组数据应该有的**权重**
- 在数据归一化中，**越大越好**的用第一种（min-max归一化/规约化）；越小越好的还需要用1减去min-amx归一化的结果，这样就转化成了**越大越好**的
- n是数据的个数，k是评价指标的个数

Python代码实现：



### 2.2 TOPSIS分析

TOPSIS的想法就是，通过一定的计算，评估方案系统中任何一个方案**距离理想最优解和最劣解的综合距离**。如果一个方案距离理想最优解越近，距离最劣解越远，我们就有理由认为这个方案更好。

那理想最优解和最劣解又是什么呢？很简单，理想最优解就是该理想最优方案的**各指标值都取到系统中评价指标的最优值**，最劣解就是该理想最劣方案的各指标值都取到系统中评价指标的最劣值。

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725110406086.png" alt="image-20220725110406086" style="zoom:67%;" />

> 与层次分析法对比，TOPSIS方法是**自底向上**的
>
> TOPSIS是先有每个**方案**的各项**准则**指标，然后对指标数据进行预处理，每个方案的各项指标构成一个行向量，再把行向量堆起来，从而形成了下面提到的**评分矩阵Z**（注意这个时候还没涉及到**权重**）

#### 2.2.1 数据预处理

> TOPSIS分析法的第一步

- 指标**正向化**：

  在处理数据时，有些指标的数据**越大越好**，有些则是越小越好，有些又是中间某个值或者某段区间最好。我们可以对其进行“正向化处理”，使指标都可以像考试分数那样，**越大越好**。

  <img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725110934427.png" alt="image-20220725110934427" style="zoom:67%;" />

  > 对于区间型和中值型也要区分是离区间/中值近一点好还是远一点好；
  >
  > 有的时候也可以用$\frac 1X$去正向化

- 指标无量纲化：

  为了消除不同的数据指标量纲的影响，我们还有必要对已经正向化的矩阵进行标准化。

  - Z-score规约就是一种方法
  -  $\frac X{\sqrt{2X^2}}$也可以

#### 2.2.2 评分

<img src="%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725112110986.png" alt="image-20220725112110986" style="zoom:60%;" />

> ！！！注意上面这个减号是距离的意思，不是直接向量相减

#### 2.2.3 总结

![image-20220725112101019](%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AF%BC%E8%AE%BA2.assets/image-20220725112101019.png)



## 3 模糊评价法

## 4 CRITICS方法

## 5 主成分分析

## 6 因子分析

## 7 数据包络分析

